{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "random.seed(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import feature_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display\n",
    "\n",
    "# Gradient Boosting\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().magic('matplotlib inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "Train shape: 4459 Rows, 4991 Columns\n",
      "Test shape: 49342 Rows, 4991 Columns\n",
      "Combine Train and Test\n",
      "\n",
      "All Data shape: 53801 Rows, 4991 Columns\n"
     ]
    }
   ],
   "source": [
    "id_col = \"ID\"\n",
    "target_var = \"target\"\n",
    "\n",
    "print(\"Loading Data...\")\n",
    "df_train = pd.read_csv(\"./train.csv\", index_col=id_col)\n",
    "training_index = df_train.index\n",
    "df_test = pd.read_csv(\"./test.csv\", index_col=id_col)\n",
    "test_index = df_test.index\n",
    "\n",
    "y = np.log1p(df_train[target_var])\n",
    "df_train.drop(target_var, axis=1, inplace=True)\n",
    "\n",
    "print('Train shape: {} Rows, {} Columns'.format(*df_train.shape))\n",
    "print('Test shape: {} Rows, {} Columns'.format(*df_test.shape))\n",
    "\n",
    "print(\"Combine Train and Test\")\n",
    "df = pd.concat([df_train, df_test], axis=0)\n",
    "del df_train, df_test\n",
    "gc.collect()\n",
    "print('\\nAll Data shape: {} Rows, {} Columns'.format(*df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LightGBM. Train shape: (4459, 4991), Test shape: (49342, 4991)\n",
      "Feature Num:  4991\n"
     ]
    }
   ],
   "source": [
    "# Modeling Datasets\n",
    "test_df = df.loc[test_index,:]\n",
    "vocab = df.columns\n",
    "\n",
    "# LGBM Dataset\n",
    "lgtrain = lgb.Dataset(df.loc[training_index,vocab],y ,feature_name = \"auto\")\n",
    "print(\"Starting LightGBM. Train shape: {}, Test shape: {}\".format(df.loc[training_index,:].shape,test_df.shape))\n",
    "print(\"Feature Num: \",len(vocab))\n",
    "del df; gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params =  {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"num_leaves\": 180,\n",
    "    \"feature_fraction\": 0.50,\n",
    "    \"bagging_fraction\": 0.50,\n",
    "    'bagging_freq': 4,\n",
    "    \"max_depth\": -1,\n",
    "    \"reg_alpha\": 0.3,\n",
    "    \"reg_lambda\": 0.1,\n",
    "    #\"min_split_gain\":0.2,\n",
    "    \"min_child_weight\":10,\n",
    "    'zero_as_missing':True,\n",
    "    'device': 'gpu',\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns = [\"Rounds\",\"Score\",\"STDV\", \"LB\", \"Parameters\"])\n",
    "# Find Optimal Parameters / Boosting Rounds\n",
    "lgb_cv = lgb.cv(\n",
    "    params = lgbm_params,\n",
    "    train_set = lgtrain,\n",
    "    num_boost_round=2000,\n",
    "    stratified=False,\n",
    "    nfold = 5,\n",
    "    verbose_eval=50,\n",
    "    seed = 23,\n",
    "    early_stopping_rounds=75)\n",
    "\n",
    "optimal_rounds = np.argmin(lgb_cv['rmse-mean'])\n",
    "best_cv_score = min(lgb_cv['rmse-mean'])\n",
    "\n",
    "print(\"\\nOptimal Round: {}\\nOptimal Score: {} + {}\".format(\n",
    "    optimal_rounds,best_cv_score,lgb_cv['rmse-stdv'][optimal_rounds]))\n",
    "\n",
    "results = results.append({\"Rounds\": optimal_rounds,\n",
    "                          \"Score\": best_cv_score,\n",
    "                          \"STDV\": lgb_cv['rmse-stdv'][optimal_rounds],\n",
    "                          \"LB\": None,\n",
    "                          \"Parameters\": lgbm_params}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 800)\n",
    "display(results.sort_values(by=\"Score\",ascending = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'feature_fraction': '0.994', 'max_depth': 6, 'num_leaves': 36}\n",
      "Optimal Round: 701\n",
      "Optimal Score: 1.4475485462521605 + 0.008393263017899597\n",
      "###########################################################################################\n",
      "Params: {'feature_fraction': '0.663', 'max_depth': 16, 'num_leaves': 60}\n",
      "Optimal Round: 393\n",
      "Optimal Score: 1.4354457219911687 + 0.005831930719646793\n",
      "###########################################################################################\n",
      "Params: {'feature_fraction': '0.851', 'max_depth': 24, 'num_leaves': 12}\n",
      "Optimal Round: 710\n",
      "Optimal Score: 1.449511279197058 + 0.009030143247951589\n",
      "###########################################################################################\n",
      "Params: {'feature_fraction': '0.815', 'max_depth': 6, 'num_leaves': 140}\n",
      "Optimal Round: 778\n",
      "Optimal Score: 1.4465160447131524 + 0.0076460385052734454\n",
      "###########################################################################################\n",
      "Params: {'feature_fraction': '0.531', 'max_depth': 16, 'num_leaves': 100}\n",
      "Optimal Round: 385\n",
      "Optimal Score: 1.4336040334796873 + 0.00642128957337911\n",
      "###########################################################################################\n",
      "Params: {'feature_fraction': '0.522', 'max_depth': 8, 'num_leaves': 100}\n",
      "Optimal Round: 707\n",
      "Optimal Score: 1.4402047070039519 + 0.007583965781729995\n",
      "###########################################################################################\n",
      "Params: {'feature_fraction': '0.961', 'max_depth': 24, 'num_leaves': 100}\n",
      "Optimal Round: 317\n",
      "Optimal Score: 1.4375758383585981 + 0.004174556590716538\n",
      "###########################################################################################\n",
      "Params: {'feature_fraction': '0.637', 'max_depth': 4, 'num_leaves': 140}\n",
      "Optimal Round: 1009\n",
      "Optimal Score: 1.4508565331488186 + 0.010244617051560568\n",
      "###########################################################################################\n",
      "Params: {'feature_fraction': '0.452', 'max_depth': 4, 'num_leaves': 12}\n",
      "Optimal Round: 1070\n",
      "Optimal Score: 1.4490712085001765 + 0.012047664397359655\n",
      "###########################################################################################\n",
      "Params: {'feature_fraction': '0.470', 'max_depth': 6, 'num_leaves': 60}\n",
      "Optimal Round: 802\n",
      "Optimal Score: 1.442594655834374 + 0.008892993296615298\n",
      "###########################################################################################\n",
      "Params: {'feature_fraction': '0.499', 'max_depth': 16, 'num_leaves': 36}\n",
      "Optimal Round: 424\n",
      "Optimal Score: 1.433892365016357 + 0.007187353495269705\n",
      "###########################################################################################\n",
      "Params: {'feature_fraction': '0.861', 'max_depth': -1, 'num_leaves': 36}\n",
      "Optimal Round: 344\n",
      "Optimal Score: 1.43833677717844 + 0.006808554910129745\n",
      "###########################################################################################\n",
      "Params: {'feature_fraction': '0.521', 'max_depth': -1, 'num_leaves': 36}\n",
      "Optimal Round: 384\n",
      "Optimal Score: 1.4333247884340974 + 0.00745235623748603\n",
      "###########################################################################################\n",
      "Params: {'feature_fraction': '0.633', 'max_depth': 4, 'num_leaves': 36}\n",
      "Optimal Round: 973\n",
      "Optimal Score: 1.4506988289015752 + 0.009328719324396328\n",
      "###########################################################################################\n",
      "Params: {'feature_fraction': '0.940', 'max_depth': 24, 'num_leaves': 140}\n",
      "Optimal Round: 309\n",
      "Optimal Score: 1.437789208489286 + 0.005414140541939249\n",
      "###########################################################################################\n",
      "Params: {'feature_fraction': '0.767', 'max_depth': -1, 'num_leaves': 100}\n",
      "Optimal Round: 306\n",
      "Optimal Score: 1.4370276483878568 + 0.006529089576765688\n",
      "###########################################################################################\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "\n",
    "results = pd.DataFrame(columns = [\"Rounds\",\"Score\",\"STDV\", \"Parameters\"])\n",
    "\n",
    "def objective(params):\n",
    "    lgbm_params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        'bagging_freq': 4,\n",
    "        \"reg_alpha\": 0.3,\n",
    "        \"reg_lambda\": 0.1,\n",
    "        \"min_child_weight\": 10,\n",
    "        'zero_as_missing': True,\n",
    "        'feature_fraction_seed': 5,\n",
    "        'device': 'gpu',\n",
    "    }\n",
    "    \n",
    "    params['num_leaves'] = int(params['num_leaves'])\n",
    "    params['feature_fraction'] = '{:.3f}'.format(params['feature_fraction'])\n",
    "    cv_params = dict(lgbm_params, **params)\n",
    "    \n",
    "    lgb_cv = lgb.cv(\n",
    "        params = cv_params,\n",
    "        train_set = lgtrain,\n",
    "        num_boost_round=2000,\n",
    "        stratified=False,\n",
    "        nfold = 3,\n",
    "        verbose_eval=10000,\n",
    "        seed = 1234,\n",
    "        early_stopping_rounds=75)\n",
    "    \n",
    "    score = np.min(lgb_cv['rmse-mean'])\n",
    "    optimal_rounds = np.argmin(lgb_cv['rmse-mean'])\n",
    "    print(\"Params: {}\".format(params))\n",
    "    print(\"Optimal Round: {}\\nOptimal Score: {} + {}\".format(\n",
    "        optimal_rounds,score,lgb_cv['rmse-stdv'][optimal_rounds]))\n",
    "    global results\n",
    "    results = results.append({\"Rounds\": optimal_rounds,\n",
    "                          \"Score\": score,\n",
    "                          \"STDV\": lgb_cv['rmse-stdv'][optimal_rounds],\n",
    "                          \"Parameters\": params}, ignore_index=True)\n",
    "    print(\"###########################################################################################\")\n",
    "\n",
    "    return score\n",
    "\n",
    "space = {\n",
    "    'num_leaves': hp.quniform('num_leaves', 40, 320, 2),\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.4, 1.0),\n",
    "    'max_depth': hp.choice('max_depth', [-1,4,6,8,12,16,24,32]),\n",
    "    'num_leaves': hp.choice('num_leaves', [12,36,60,100,140,180])\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.05, 0.02, 0.01 ,0.005]\n",
    "for param in learning_rates:\n",
    "    print(\"Learning Rate: \", param)\n",
    "    lgbm_params[\"learning_rate\"] = param\n",
    "    # Find Optimal Parameters / Boosting Rounds\n",
    "    lgb_cv = lgb.cv(\n",
    "        params = lgbm_params,\n",
    "        train_set = lgtrain,\n",
    "        num_boost_round=10000,\n",
    "        stratified=False,\n",
    "        nfold = 5,\n",
    "        verbose_eval=200,\n",
    "        seed = 23,\n",
    "        early_stopping_rounds=75)\n",
    "\n",
    "    optimal_rounds = np.argmin(lgb_cv['rmse-mean'])\n",
    "    best_cv_score = min(lgb_cv['rmse-mean'])\n",
    "\n",
    "    print(\"Optimal Round: {}\\nOptimal Score: {} + {}\".format(\n",
    "        optimal_rounds,best_cv_score,lgb_cv['rmse-stdv'][optimal_rounds]))\n",
    "    print(\"###########################################################################################\")\n",
    "\n",
    "    results = results.append({\"Rounds\": optimal_rounds,\n",
    "                              \"Score\": best_cv_score,\n",
    "                              \"STDV\": lgb_cv['rmse-stdv'][optimal_rounds],\n",
    "                              \"LB\": None,\n",
    "                              \"Parameters\": lgbm_params}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 800)\n",
    "display(results.sort_values(by=\"Score\",ascending = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Parameters\n",
    "final_model_params = results.iloc[results[\"Score\"].idxmin(),:][\"Parameters\"]\n",
    "optimal_rounds = results.iloc[results[\"Score\"].idxmin(),:][\"Rounds\"]\n",
    "print(\"Parameters for Final Models:\\n\",final_model_params)\n",
    "print(\"Score: {} +/- {}\".format(results.iloc[results[\"Score\"].idxmin(),:][\"Score\"],results.iloc[results[\"Score\"].idxmin(),:][\"STDV\"]))\n",
    "print(\"Rounds: \", optimal_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Model with different Seeds\n",
    "multi_seed_pred = dict()\n",
    "all_feature_importance_df  = pd.DataFrame()\n",
    "\n",
    "all_seeds = [0,20,400,4000,20000]\n",
    "for seeds_x in all_seeds:\n",
    "    print(\"Seed: \", seeds_x,)\n",
    "    final_model_params[\"seed\"] = seeds_x\n",
    "    lgb_reg = lgb.train(\n",
    "        final_model_params,\n",
    "        lgtrain,\n",
    "        num_boost_round = optimal_rounds + 1,\n",
    "        verbose_eval=200)\n",
    "\n",
    "    # Feature Importance\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = vocab\n",
    "    fold_importance_df[\"importance\"] = lgb_reg.feature_importance()\n",
    "    all_feature_importance_df = pd.concat([all_feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    multi_seed_pred[seeds_x] =  list(lgb_reg.predict(test_df))\n",
    "    print(\"###########################################################################################\")\n",
    "    del lgb_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = all_feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "    by=\"importance\", ascending=False)[:50].index\n",
    "best_features = all_feature_importance_df.loc[all_feature_importance_df.feature.isin(cols)]\n",
    "plt.figure(figsize=(8,10))\n",
    "sns.barplot(x=\"importance\", y=\"feature\", \n",
    "            data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances.png')\n",
    "\n",
    "# To DataFrame\n",
    "sub_preds = pd.DataFrame.from_dict(multi_seed_pred).replace(0,0.000001)\n",
    "del multi_seed_pred; gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take Mean over Seed prediction\n",
    "mean_sub = np.expm1(sub_preds.mean(axis=1).rename(target_var))\n",
    "mean_sub.index = test_index\n",
    "\n",
    "# Submit\n",
    "mean_sub.to_csv('mean_sub_ep{}_sc{}.csv'.format(optimal_rounds,round(best_cv_score,5))\n",
    "            ,index = True, header=True)\n",
    "mean_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
